package executor

import (
	"bytes"
	"context"
	"encoding/json"
	"fmt"
	"io"
	"net/http"
	"time"
)

// BigModelExecutor æ™ºè°± AI BigModel æ‰§è¡Œå™¨
type BigModelExecutor struct {
	client *http.Client
	apiKey string
	apiURL string
}

// NewBigModelExecutor åˆ›å»º BigModel æ‰§è¡Œå™¨
func NewBigModelExecutor(apiKey string) *BigModelExecutor {
	return &BigModelExecutor{
		client: &http.Client{
			Timeout: 120 * time.Second,
		},
		apiKey: apiKey,
		apiURL: "https://open.bigmodel.cn/api/paas/v4/chat/completions",
	}
}

// Name è¿”å›æ‰§è¡Œå™¨åç§°
func (e *BigModelExecutor) Name() string {
	return "bigmodel_analysis"
}

// Execute æ‰§è¡Œä»»åŠ¡
func (e *BigModelExecutor) Execute(ctx context.Context, input map[string]interface{}, jobContext map[string]string) (map[string]interface{}, error) {
	// ä» job context è·å–è½¬å½•æ–‡æœ¬
	transcript := jobContext["transcript"]
	if transcript == "" {
		// å¦‚æœ context ä¸­æ²¡æœ‰ï¼Œå°è¯•ä» input è·å–
		if t, ok := input["transcript"].(string); ok {
			transcript = t
		} else {
			return nil, fmt.Errorf("missing transcript in job context")
		}
	}

	// æ£€æŸ¥æ–‡æœ¬é•¿åº¦
	if len(transcript) > 10000 {
		transcript = transcript[:10000] + "..." // æˆªæ–­è¿‡é•¿çš„æ–‡æœ¬
	}

	// ç”Ÿæˆå¤šä¸ªåˆ†æç»“æœ
	results := make(map[string]interface{})

	// 1. ç”Ÿæˆé˜…è¯»æ‘˜è¦
	summary, err := e.generateContent(ctx, transcript, "summary")
	if err != nil {
		return nil, fmt.Errorf("failed to generate summary: %w", err)
	}
	results["summary"] = summary

	// 2. ç”Ÿæˆæ€ç»´å¯¼å›¾
	mindmap, err := e.generateContent(ctx, transcript, "mindmap")
	if err != nil {
		return nil, fmt.Errorf("failed to generate mindmap: %w", err)
	}
	results["mindmap"] = mindmap

	// 3. é‡ç‚¹åˆ†æ
	keyPoints, err := e.generateContent(ctx, transcript, "key_points")
	if err != nil {
		return nil, fmt.Errorf("failed to generate key points: %w", err)
	}
	results["key_points"] = keyPoints

	// 4. ä¸ªäººè®¤çŸ¥
	insights, err := e.generateContent(ctx, transcript, "insights")
	if err != nil {
		return nil, fmt.Errorf("failed to generate insights: %w", err)
	}
	results["insights"] = insights

	return results, nil
}

// generateContent ç”Ÿæˆç‰¹å®šç±»å‹çš„å†…å®¹
func (e *BigModelExecutor) generateContent(ctx context.Context, transcript, contentType string) (string, error) {
	// æ ¹æ®å†…å®¹ç±»å‹æ„å»ºä¸åŒçš„æç¤ºè¯
	prompt := e.buildPrompt(transcript, contentType)

	// å¦‚æœæ²¡æœ‰é…ç½® API keyï¼Œè¿”å›æ¨¡æ‹Ÿæ•°æ®
	if e.apiKey == "" || e.apiKey == "your_api_key_here" {
		return e.getMockContent(contentType, transcript), nil
	}

	// è°ƒç”¨ BigModel API
	request := BigModelRequest{
		Model: "glm-4-air",
		Messages: []Message{
			{
				Role:    "user",
				Content: prompt,
			},
		},
		Temperature: 0.7,
		TopP:        0.9,
	}

	requestBody, err := json.Marshal(request)
	if err != nil {
		return "", fmt.Errorf("failed to marshal request: %w", err)
	}

	req, err := http.NewRequestWithContext(ctx, "POST", e.apiURL, bytes.NewReader(requestBody))
	if err != nil {
		return "", fmt.Errorf("failed to create request: %w", err)
	}

	req.Header.Set("Content-Type", "application/json")
	req.Header.Set("Authorization", fmt.Sprintf("Bearer %s", e.apiKey))

	resp, err := e.client.Do(req)
	if err != nil {
		return "", fmt.Errorf("failed to call API: %w", err)
	}
	defer resp.Body.Close()

	body, err := io.ReadAll(resp.Body)
	if err != nil {
		return "", fmt.Errorf("failed to read response: %w", err)
	}

	if resp.StatusCode != http.StatusOK {
		return "", fmt.Errorf("API returned error: %s, body: %s", resp.Status, string(body))
	}

	var response BigModelResponse
	if err := json.Unmarshal(body, &response); err != nil {
		return "", fmt.Errorf("failed to unmarshal response: %w", err)
	}

	if len(response.Choices) == 0 {
		return "", fmt.Errorf("no choices in response")
	}

	return response.Choices[0].Message.Content, nil
}

// buildPrompt æ„å»ºæç¤ºè¯
func (e *BigModelExecutor) buildPrompt(transcript, contentType string) string {
	prompts := map[string]string{
		"summary": fmt.Sprintf(`è¯·åŸºäºä»¥ä¸‹è§†é¢‘è½¬å½•å†…å®¹ï¼Œç”Ÿæˆä¸€ç¯‡ç®€æ´çš„é˜…è¯»æ‘˜è¦ï¼ˆ300-500å­—ï¼‰ã€‚
è¦æ±‚ï¼š
1. æ¦‚æ‹¬è§†é¢‘çš„ä¸»è¦ä¸»é¢˜å’Œæ ¸å¿ƒè§‚ç‚¹
2. ä½¿ç”¨æ¸…æ™°çš„æ®µè½ç»“æ„
3. çªå‡ºå…³é”®ä¿¡æ¯å’Œé‡è¦ç»“è®º

è§†é¢‘è½¬å½•å†…å®¹ï¼š
%s

è¯·ç”Ÿæˆæ‘˜è¦ï¼š`, transcript),

		"mindmap": fmt.Sprintf(`è¯·åŸºäºä»¥ä¸‹è§†é¢‘è½¬å½•å†…å®¹ï¼Œç”Ÿæˆä¸€ä¸ªç»“æ„åŒ–çš„æ€ç»´å¯¼å›¾ï¼ˆä½¿ç”¨ Markdown æ ¼å¼ï¼‰ã€‚
è¦æ±‚ï¼š
1. ä½¿ç”¨åˆ†å±‚çš„åˆ—è¡¨ç»“æ„
2. ç¬¬ä¸€å±‚æ˜¯ä¸»é¢˜
3. ç¬¬äºŒå±‚æ˜¯å…³é”®è¦ç‚¹
4. ç¬¬ä¸‰å±‚æ˜¯å…·ä½“ç»†èŠ‚
5. ä½¿ç”¨ç®€æ´çš„çŸ­è¯­

è§†é¢‘è½¬å½•å†…å®¹ï¼š
%s

è¯·ç”Ÿæˆæ€ç»´å¯¼å›¾ï¼ˆMarkdown æ ¼å¼ï¼‰ï¼š`, transcript),

		"key_points": fmt.Sprintf(`è¯·åŸºäºä»¥ä¸‹è§†é¢‘è½¬å½•å†…å®¹ï¼Œæå–å¹¶åˆ†æé‡ç‚¹å†…å®¹ã€‚
è¦æ±‚ï¼š
1. åˆ—å‡º 5-8 ä¸ªå…³é”®è¦ç‚¹
2. æ¯ä¸ªè¦ç‚¹åŒ…å«ç®€çŸ­çš„è§£é‡Š
3. æ ‡æ³¨é‡è¦æ€§ç­‰çº§ï¼ˆâ­â­â­ é«˜ / â­â­ ä¸­ / â­ ä½ï¼‰
4. ä½¿ç”¨ Markdown æ ¼å¼

è§†é¢‘è½¬å½•å†…å®¹ï¼š
%s

è¯·ç”Ÿæˆé‡ç‚¹åˆ†æï¼š`, transcript),

		"insights": fmt.Sprintf(`è¯·åŸºäºä»¥ä¸‹è§†é¢‘è½¬å½•å†…å®¹ï¼Œæä¾›ä¸ªäººè®¤çŸ¥å’Œæ·±åº¦æ€è€ƒã€‚
è¦æ±‚ï¼š
1. ä»ä¸åŒè§’åº¦åˆ†æè§†é¢‘å†…å®¹çš„ä»·å€¼
2. æå‡ºå¯èƒ½çš„å»¶ä¼¸æ€è€ƒæˆ–åº”ç”¨åœºæ™¯
3. æŒ‡å‡ºå†…å®¹çš„å±€é™æ€§æˆ–å¯æ”¹è¿›ä¹‹å¤„
4. æ€»ç»“ä¸ªäººæ”¶è·å’Œå¯å‘
5. ä½¿ç”¨ Markdown æ ¼å¼

è§†é¢‘è½¬å½•å†…å®¹ï¼š
%s

è¯·ç”Ÿæˆä¸ªäººè®¤çŸ¥ï¼š`, transcript),
	}

	prompt, ok := prompts[contentType]
	if !ok {
		return transcript
	}

	return prompt
}

// getMockContent è¿”å›æ¨¡æ‹Ÿå†…å®¹ï¼ˆç”¨äºæ¼”ç¤ºï¼‰
func (e *BigModelExecutor) getMockContent(contentType, transcript string) string {
	// åˆ†æè½¬å½•æ–‡æœ¬çš„å…³é”®è¯
	keywords := e.extractKeywords(transcript)

	mockContent := map[string]string{
		"summary": fmt.Sprintf(`# è§†é¢‘æ‘˜è¦

æœ¬è§†é¢‘ä¸»è¦æ¢è®¨äº†å…³äº %s çš„æ ¸å¿ƒæ¦‚å¿µå’Œå®é™…åº”ç”¨ã€‚

## ä¸»è¦å†…å®¹

è§†é¢‘å¼€å¤´ä»‹ç»äº†åŸºç¡€æ¦‚å¿µï¼Œéšåæ·±å…¥è®²è§£äº†ç›¸å…³æŠ€æœ¯ç»†èŠ‚ã€‚è®²è€…é€šè¿‡å®ä¾‹æ¼”ç¤ºï¼Œå¸®åŠ©è§‚ä¼—æ›´å¥½åœ°ç†è§£è¿™äº›æŠ½è±¡çš„æ¦‚å¿µã€‚

## æ ¸å¿ƒè§‚ç‚¹

1. **ç†è®ºåŸºç¡€**ï¼šè¯¦ç»†é˜è¿°äº† %s çš„ç†è®ºæ¡†æ¶
2. **å®è·µåº”ç”¨**ï¼šå±•ç¤ºäº†å¤šä¸ªçœŸå®åœºæ™¯çš„åº”ç”¨æ¡ˆä¾‹
3. **æœªæ¥è¶‹åŠ¿**ï¼šæ¢è®¨äº†è¯¥é¢†åŸŸçš„å‘å±•æ–¹å‘å’Œæ½œåœ¨æœºä¼š

## æ€»ç»“

è¿™æ˜¯ä¸€ä¸ªå†…å®¹ä¸°å¯Œã€ç»“æ„æ¸…æ™°çš„æ•™å­¦è§†é¢‘ï¼Œé€‚åˆåˆå­¦è€…äº†è§£ç›¸å…³çŸ¥è¯†ï¼Œä¹Ÿä¸ºæœ‰ä¸€å®šåŸºç¡€çš„å­¦ä¹ è€…æä¾›äº†æ–°çš„è§†è§’ã€‚`, keywords, keywords),

		"mindmap": fmt.Sprintf(`# è§†é¢‘æ€ç»´å¯¼å›¾

## ğŸ¯ æ ¸å¿ƒä¸»é¢˜ï¼š%s

### ğŸ“š åŸºç¡€æ¦‚å¿µ
- å®šä¹‰å’ŒèƒŒæ™¯
  - å†å²å‘å±•
  - æ ¸å¿ƒç†è®º
- ç›¸å…³æŠ€æœ¯
  - æŠ€æœ¯æ ˆ
  - å·¥å…·é“¾

### ğŸ’¡ å…³é”®è¦ç‚¹
- ä¸»è¦ç‰¹æ€§
  - ä¼˜åŠ¿åˆ†æ
  - åº”ç”¨åœºæ™¯
- å®ç°æ–¹æ³•
  - æŠ€æœ¯ç»†èŠ‚
  - æœ€ä½³å®è·µ

### ğŸš€ å®è·µåº”ç”¨
- æ¡ˆä¾‹åˆ†æ
  - æˆåŠŸæ¡ˆä¾‹
  - ç»éªŒæ€»ç»“
- å®æ–½æ­¥éª¤
  - å‡†å¤‡å·¥ä½œ
  - æ‰§è¡Œè®¡åˆ’

### ğŸ”® æœªæ¥å±•æœ›
- å‘å±•è¶‹åŠ¿
- æŒ‘æˆ˜ä¸æœºé‡`, keywords),

		"key_points": fmt.Sprintf(`# é‡ç‚¹åˆ†æ

## â­â­â­ é«˜ä¼˜å…ˆçº§è¦ç‚¹

### 1. æ ¸å¿ƒæ¦‚å¿µç†è§£
%s æ˜¯æœ¬è§†é¢‘çš„æ ¸å¿ƒä¸»é¢˜ï¼Œç†è§£å…¶æœ¬è´¨å¯¹åç»­å­¦ä¹ è‡³å…³é‡è¦ã€‚

### 2. å®é™…åº”ç”¨åœºæ™¯
è§†é¢‘å±•ç¤ºäº†å¤šä¸ªçœŸå®æ¡ˆä¾‹ï¼Œè¿™äº›æ¡ˆä¾‹å¯ä»¥ç›´æ¥åº”ç”¨åˆ°å®é™…å·¥ä½œä¸­ã€‚

## â­â­ ä¸­ä¼˜å…ˆçº§è¦ç‚¹

### 3. æŠ€æœ¯å®ç°ç»†èŠ‚
è®²è§£äº†å…·ä½“çš„æŠ€æœ¯å®ç°æ–¹æ³•ï¼ŒåŒ…æ‹¬å·¥å…·é€‰æ‹©å’Œé…ç½®æ–¹å¼ã€‚

### 4. å¸¸è§é—®é¢˜è§£ç­”
æ€»ç»“äº†å­¦ä¹ è¿‡ç¨‹ä¸­å®¹æ˜“é‡åˆ°çš„é—®é¢˜åŠå…¶è§£å†³æ–¹æ¡ˆã€‚

## â­ è¡¥å……è¦ç‚¹

### 5. æ‰©å±•é˜…è¯»èµ„æº
æä¾›äº†é¢å¤–çš„å­¦ä¹ èµ„æºå’Œå‚è€ƒææ–™ã€‚

### 6. ç¤¾åŒºå’Œç”Ÿæ€
ä»‹ç»äº†ç›¸å…³çš„å¼€æºé¡¹ç›®å’Œç¤¾åŒºèµ„æºã€‚`, keywords),

		"insights": fmt.Sprintf(`# ä¸ªäººè®¤çŸ¥ä¸æ€è€ƒ

## ğŸ’­ å†…å®¹ä»·å€¼åˆ†æ

è¿™ä¸ªè§†é¢‘ä»å¤šä¸ªç»´åº¦å±•ç°äº† %s çš„å…¨è²Œï¼Œä¸ä»…åŒ…æ‹¬ç†è®ºçŸ¥è¯†ï¼Œè¿˜ç»“åˆäº†å®è·µç»éªŒã€‚

### ç†è®ºå±‚é¢
è§†é¢‘æ„å»ºäº†å®Œæ•´çš„çŸ¥è¯†æ¡†æ¶ï¼Œå¸®åŠ©è§‚ä¼—å»ºç«‹ç³»ç»Ÿæ€§çš„ç†è§£ã€‚

### å®è·µå±‚é¢
é€šè¿‡å…·ä½“æ¡ˆä¾‹ï¼Œå±•ç¤ºäº†ç†è®ºå¦‚ä½•è½¬åŒ–ä¸ºå®é™…åº”ç”¨ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯å»¶ä¼¸

1. **æ•™è‚²åŸ¹è®­**ï¼šå¯ä»¥ä½œä¸ºæ•™å­¦ææ–™ä½¿ç”¨
2. **é¡¹ç›®å¼€å‘**ï¼šæä¾›äº†å¯å€Ÿé‰´çš„å®æ–½æ–¹æ¡ˆ
3. **æŠ€æœ¯ç ”ç©¶**ï¼šä¸ºè¿›ä¸€æ­¥ç ”ç©¶æä¾›äº†æ–¹å‘

## ğŸ” æ‰¹åˆ¤æ€§æ€è€ƒ

### ä¼˜åŠ¿
- å†…å®¹ç»“æ„æ¸…æ™°
- è®²è§£æ·±å…¥æµ…å‡º
- æ¡ˆä¾‹ä¸°å¯Œå®ç”¨

### å¯æ”¹è¿›ä¹‹å¤„
- æŸäº›æŠ€æœ¯ç»†èŠ‚å¯ä»¥è¿›ä¸€æ­¥å±•å¼€
- å¯ä»¥å¢åŠ æ›´å¤šå¯¹æ¯”åˆ†æ
- å»ºè®®è¡¥å……æœ€æ–°çš„å‘å±•åŠ¨æ€

## ğŸ’¡ ä¸ªäººæ”¶è·

é€šè¿‡è¿™ä¸ªè§†é¢‘ï¼Œæˆ‘å¯¹ %s æœ‰äº†æ›´æ·±å…¥çš„ç†è§£ï¼Œç‰¹åˆ«æ˜¯åœ¨å®é™…åº”ç”¨æ–¹é¢è·å¾—äº†å¾ˆå¤šå¯å‘ã€‚å»ºè®®ç»“åˆç›¸å…³æ–‡æ¡£å’Œå®è·µé¡¹ç›®ï¼Œè¿›ä¸€æ­¥å·©å›ºæ‰€å­¦çŸ¥è¯†ã€‚`, keywords, keywords),
	}

	content, ok := mockContent[contentType]
	if !ok {
		return "å†…å®¹ç”Ÿæˆä¸­..."
	}

	return content
}

// extractKeywords ä»æ–‡æœ¬ä¸­æå–å…³é”®è¯ï¼ˆç®€å•å®ç°ï¼‰
func (e *BigModelExecutor) extractKeywords(text string) string {
	keywords := []string{
		"artificial intelligence", "machine learning", "deep learning",
		"neural networks", "data science", "technology",
	}

	text = text[:min(500, len(text))]
	for _, keyword := range keywords {
		if contains(text, keyword) {
			return keyword
		}
	}

	return "ç›¸å…³ä¸»é¢˜"
}

func contains(text, substr string) bool {
	return len(text) >= len(substr) && (text[:len(substr)] == substr || contains(text[1:], substr))
}

func min(a, b int) int {
	if a < b {
		return a
	}
	return b
}

// BigModel API è¯·æ±‚ç»“æ„
type BigModelRequest struct {
	Model       string    `json:"model"`
	Messages    []Message `json:"messages"`
	Temperature float64   `json:"temperature,omitempty"`
	TopP        float64   `json:"top_p,omitempty"`
}

type Message struct {
	Role    string `json:"role"`
	Content string `json:"content"`
}

// BigModel API å“åº”ç»“æ„
type BigModelResponse struct {
	ID      string   `json:"id"`
	Created int64    `json:"created"`
	Model   string   `json:"model"`
	Choices []Choice `json:"choices"`
	Usage   Usage    `json:"usage"`
}

type Choice struct {
	Index        int     `json:"index"`
	Message      Message `json:"message"`
	FinishReason string  `json:"finish_reason"`
}

type Usage struct {
	PromptTokens     int `json:"prompt_tokens"`
	CompletionTokens int `json:"completion_tokens"`
	TotalTokens      int `json:"total_tokens"`
}
